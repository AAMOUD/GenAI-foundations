{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Markov Chain as a Text Generator**\n",
    "\n",
    "In the context of text generation, a *Markov Chain* can be used to generate text by modeling words as states and defining the probability of one word following another based on the training corpus. The idea is to learn the probability of transitioning from one word to another, and then use this to generate new text based on the learned probabilities.\n",
    "\n",
    "For example, from the corpus:\n",
    "\n",
    "**I love programming in Python**\n",
    "\n",
    "You can build a transition matrix for the words, such as:\n",
    "\n",
    "From \"I\" to \"love\" = 1.0 (100% chance)\n",
    "\n",
    "From \"love\" to \"programming\" = 1.0\n",
    "\n",
    "From \"programming\" to \"in\" = 1.0\n",
    "\n",
    "From \"in\" to \"Python\" = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Markov Chains are fascinating. They allow us to generate sequences that resemble the training data. \n",
    "With enough data, these chains can produce realistic sentences. However, their simplicity has limitations.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Cleans and tokenizes input text.\n",
    "    - Removes special characters\n",
    "    - Converts text to lowercase\n",
    "    - Splits into words\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    words = text.split()\n",
    "    return words\n",
    "\n",
    "tokens = preprocess_text(text)\n",
    "print(\"Tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_transition_matrix(tokens):\n",
    "    \"\"\"\n",
    "    Builds a transition matrix from the tokenized text.\n",
    "    \"\"\"\n",
    "    matrix = defaultdict(lambda: defaultdict(int))\n",
    "    for i in range(len(tokens) - 1):\n",
    "        current_word = tokens[i]\n",
    "        next_word = tokens[i + 1]\n",
    "        matrix[current_word][next_word] += 1\n",
    "\n",
    "    # Normalize the matrix to probabilities\n",
    "    for current_word, transitions in matrix.items():\n",
    "        total = sum(transitions.values())\n",
    "        matrix[current_word] = {word: count / total for word, count in transitions.items()}\n",
    "    return matrix\n",
    "\n",
    "transition_matrix = build_transition_matrix(tokens)\n",
    "print(\"Transition Matrix (Sample):\", dict(list(transition_matrix.items())[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def generate_text(start_word, transition_matrix, length=20):\n",
    "    \"\"\"\n",
    "    Generates text using the Markov Chain transition matrix.\n",
    "    - start_word: Starting word for the generation.\n",
    "    - transition_matrix: The transition matrix.\n",
    "    - length: Number of words to generate.\n",
    "    \"\"\"\n",
    "    current_word = start_word\n",
    "    generated_text = [current_word]\n",
    "    for _ in range(length - 1):\n",
    "        if current_word not in transition_matrix:\n",
    "            break\n",
    "        next_word = random.choices(\n",
    "            list(transition_matrix[current_word].keys()), \n",
    "            weights=transition_matrix[current_word].values()\n",
    "        )[0]\n",
    "        generated_text.append(next_word)\n",
    "        current_word = next_word\n",
    "    return ' '.join(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "start_word = \"markov\"\n",
    "generated_text = generate_text(start_word, transition_matrix)\n",
    "print(\"\\nGenerated Text:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_transition_matrix(transition_matrix):\n",
    "    \"\"\"\n",
    "    Visualizes the transition matrix using a heatmap.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(transition_matrix).fillna(0)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(df, cmap=\"coolwarm\", annot=False)\n",
    "    plt.title(\"Transition Matrix Heatmap\")\n",
    "    plt.xlabel(\"Next Word\")\n",
    "    plt.ylabel(\"Current Word\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "matrix_for_visualization = {\n",
    "    key: {k: v for k, v in value.items()} for key, value in transition_matrix.items()\n",
    "}\n",
    "visualize_transition_matrix(matrix_for_visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentation with Higher-Order Markov Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_higher_order_matrix(tokens, order=2):\n",
    "    \"\"\"\n",
    "    Builds a higher-order Markov Chain transition matrix.\n",
    "    - order: The order of the Markov Chain (e.g., bigram, trigram).\n",
    "    \"\"\"\n",
    "    matrix = defaultdict(lambda: defaultdict(int))\n",
    "    for i in range(len(tokens) - order):\n",
    "        current_state = tuple(tokens[i:i + order])\n",
    "        next_word = tokens[i + order]\n",
    "        matrix[current_state][next_word] += 1\n",
    "\n",
    "    for current_state, transitions in matrix.items():\n",
    "        total = sum(transitions.values())\n",
    "        matrix[current_state] = {word: count / total for word, count in transitions.items()}\n",
    "    return matrix\n",
    "\n",
    "higher_order_matrix = build_higher_order_matrix(tokens, order=2)\n",
    "print(\"Higher-Order Transition Matrix (Sample):\", dict(list(higher_order_matrix.items())[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def generate_text_higher_order(start_state, transition_matrix, length=20):\n",
    "    \"\"\"\n",
    "    Generates text using a higher-order Markov Chain transition matrix.\n",
    "    - start_state: Starting tuple for the generation.\n",
    "    - transition_matrix: The transition matrix.\n",
    "    - length: Number of words to generate.\n",
    "    \"\"\"\n",
    "    current_state = start_state\n",
    "    generated_text = list(current_state)\n",
    "    for _ in range(length - len(current_state)):\n",
    "        if current_state not in transition_matrix:\n",
    "            break\n",
    "        next_word = random.choices(\n",
    "            list(transition_matrix[current_state].keys()), \n",
    "            weights=transition_matrix[current_state].values()\n",
    "        )[0]\n",
    "        generated_text.append(next_word)\n",
    "        current_state = tuple(generated_text[-len(current_state):])\n",
    "    return ' '.join(generated_text)\n",
    "\n",
    "start_state = (\"markov\", \"chains\")\n",
    "generated_higher_order_text = generate_text_higher_order(start_state, higher_order_matrix)\n",
    "print(\"\\nGenerated Higher-Order Text:\", generated_higher_order_text)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
